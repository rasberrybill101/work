Use Python for this implementation:
Given a tab-separated file "train_data_v3_metadata.tsv" with columns: 
conv_id
label
call_duration
reason_level_1
reason_level_2
plain_whisper

and a dictionary of phrases and sentences:
{ "call_handling" : ["got wrong information from ... agent",
                     "amount quoted by agent ... incorrect",
					 "was not called back",
					 "no one followed up",
					 "you ... did not follow up",
					 "you ... didn't follow up",
					 "agent ... rude",
					 "you are ... rude",
					 "I was ... cut off",
					 "agent ... tell me ... going to put me on hold"
					 ],
  "payments_transactions" : ["stop payment ... wrong amount",
							 "they said they ... stop the payment",
							 "deposit should ... be more",
							 "deposit should ... been more",
							 "deposit ... for ... different account",
							 "deposit is missing"
							],
  "card" : [ "card not arrived",
			 "card ... not arrive",
			 "card doesn't work",
			 "card does not work",
			 "didn't receive card",
			 "did not receive ... card",
			 "cannot see ... CVV",
			 "chip ... damaged"
			],
  "claims" : ["I already filed ... why ... again",
			  "I never reported ... fraud",
			  "I never applied for ... card",
			  "I've never applied for ... card"
			 ],
  "transfers_disconnects" : ["agent hung up ... me",
							 "you kept transferring me",
							 "you ... routed me ... wrong",
							 "why am I talking ... you"
			 ]
}

The task is to search in the "plain_whisper" column for phrases similar to the phrases of each key in the dictionary.
The ellipsis (the 3 dots ...) in each phrase in the vocabulary means up to 3 words. Therefore any piece of text in the plain_whisper column will be considered a match if it matches a phrase in the vocabulary after the ellipsis (if present) has been taken into account. For example:
"I never applied for zero APR credit card"
would match "I never applied for ... card" since up to 3 tokens (eg. zero APR credit) can be substituted in the dictionary phrase and have it match the phrase in the plain_whisper column
To improve performance, all comparisons should be done in lower case.

If a match is found, then we want to know the corresponding values of conv_id, reason_level_1, complaint_disat, dictionary_key, matching_sentence

where matching_sentence is the entire sentence that the matching fragment of text was found.

All matches should then be written to a csv file, using the columns: conv_id, reason_level_1, complaint_disat, dictionary_key, matching_sentence





This is the spec for a web app that consists of a frontend UI and a python backend. For the python backend, initially, there will be a single text file called "train_data_v3_metadata.tsv" which is a tab-separated file with the following columns:
conv_id
label
call_duration
reason_level_1
reason_level_2
plain_whisper

This file will be in the directory "data/training".

Write the following functions (to be used internally on the backend) to return different data from "training_data.txt":
1) "get_conv_ids()" returns the list of all conv_id values
2) "get_text_for_conv_id(conv_id: str) -> str" returns the plain_whisper value
3) "get_conv_ids_for_level_1(reason_level_1: str)" returns the list of conv_ids for given reason_level_1
4) "get_conv_ids_for_phrase(phrase: str)" returns list of conv_ids where the phrase is contained in plain_whisper columns
5) "get_conv_ids_for_complaints()" returns list of conv_ids where label column = "Not a Complaint"

Please use the following definition of sentences for some of the other functions:
def extract_sentences(text):
	sentences = re.split(r'(?<!\w\.\w.)(?<![A-Z][a-z]\.)(?<=\.(?!\d)|\?|!)\s', text)
    return sentences

6) "get_sentences_for_phrase(phrase: str)" returns a list of dictionary objects where each element in the dictionary consists of a conv_id (the key), and the sentence (or sentences) that contains the phrase (the value)

7) "get_sentence_count(conv_id)" returns the number of sentences in plain_whisper column of conv_id
8) "get_token_count(conv_id)" returns the number of words in plain_whisper column of conv_id
9) "get_all_token_count" returns the number of words in plain_whisper column of all conv_ids
10) "get_distinct_token_count" returns the number of unique words in plain_whisper column of all conv_ids

The directory structure of the web app will be as follows

  /html
    index.html
  /css
    style.css
  /js
    main.js
  /images
  /data
    /training
	   train_data_v3_metadata.tsv
	   
place the utility python functions in an appropriate location. These functions will be used during calls that will originate from POST or GET requests in the UI.