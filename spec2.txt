Given a conv. id, check if a given substring is present in any of the chunks associated with the conversation.
Confirm that what is reported as "chunk" and "history" actually match what is expected.
Compare the prediction from the batch model to the labeled ground truth.
Use a heat map to highlight the differences.
Use a confusion matrix to provide numerical metrics from the heat map.
For the heat map, compare (chunk conv id label) to (conv id label)
Number of UP chunks in a conversation
Number of tokens before the first UP chunk
Length of the first UP chunk should be equal to, or greater than the number of history chunks (this is the "effective sustained" length of the traveling chunk.
Are there transition frames more significant than the first transition frame? What determines such significance.

check if a word contains a character

======================================================

The goal is to convert a conversation into a vector representation using a function called "convToVector". A conversation is a list of sentences extracted using the function "extract_sentences" when given the entire text of a conversation as follows:
def extract_sentences(text):
    sentences = re.split(r'(?<!\w\.\w.)(?<![A-Z][a-z]\.)(?<=\.|\?|!)\s', text)
    return sentences

The vector representing a conversation is built up from the vectors representation of the individual sentences in the conversation as follows: 

There is a dictionary of key-value pairs ("signalsDictionary") whose keys are "s1","s2","s3", ... "sN"  where s1 through sN are the dictionary keys (the "signals"). For instance, if there are 10 signals, then the keys would be "s1" through "s10". For each key, the value is a list of strings (phrases that comprise one or more space-separated tokens). A vector of length N is a list of N real numbers initialized to zero as follows:
convVector = [0, 0, 0, 0, ... 0]
After the convVector has been initialized, it is then built up using the vectors of the individual sentences of the conversation.
For each sentence, a vector (of the same size as the convVector)
sentenceVector is initialized to [0, 0, 0, 0, ... 0] 
The sentence is checked for the occurrence of one or more phrases associated with each key. If a phrase is found (sentence contains the entire phrase), then the value in sentenceVector that corresponds to the position of the key is incremented by 1. For example, if phrase matches are found at positions 1, 4, and 6 (keys "s1", "s4", and "s6") then the sentenceVector will be:
[1, 0, 0, 1, 0, 1, 0, 0, 0, 0]
Thus, the values in each sentence of the conversation is used to update the convVector simply by updating convVector by adding each sentenceVector to it.
To keep the implementation flexible so that we can easily change how the vector is updated, then write a function "getSentenceVector" that takes a sentence, and the list of phrases, then returns a single sentence vector.
The function "getSentenceVector(sentence, signalDictionary)" can then be called from within "getConversationVector(convText, signalDictionary, normalize=True)" where the vector of the conversation is obtained by summing the vectors of all individual sentences in the conversation. If normalize is True, then the values in the conversation vector are scaled such that the max. value of any entry in the vector is 1. For example the vector:
[8, 2, 0, 4] would become [1, 0.25, 0, 0.5]
Note that the reason for having a separate "getSentenceVector" function is because want to have a flexible way of defining how a vector is obtained from a sentence given the phrase dictionary.

------------------------------ implementation
#==================================================
# create conversation vector from sentence vectors
#==================================================
import numpy as np
import re

def extract_sentences(text): # Split on period, ?, and !
    sentences = re.split(r'(?<!\w\.\w.)(?<![A-Z][a-z]\.)(?<=\.|\?|!)\s', text)
    return sentences  # list of sentences

def getSentenceVector(sentence, signalDictionary):
    sentenceVector = np.zeros(len(signalDictionary))  # Initialize the sentence vector
    for i, key in enumerate(signalDictionary.keys()):  # Go through each signal in the dictionary
        for phrase in signalDictionary[key]:  # Go through each phrase associated with the signal
            if phrase in sentence:  # If the phrase is in the sentence
                sentenceVector[i] += 1  # Increment the corresponding position in the sentence vector
    return sentenceVector


def getConversationVector(convText, signalDictionary, normalize=True):
    convVector = np.zeros(len(signalDictionary))  # Initialize the conversation vector
    sentences = extract_sentences(convText)  # Extract sentences from the conversation
    for sentence in sentences:  # Go through each sentence
        sentenceVector = getSentenceVector(sentence, signalDictionary)  # Get the vector for the sentence
        convVector += sentenceVector  # Add the sentence vector to the conversation vector
    
    if normalize:  # If we want to normalize the conversation vector
        max_value = np.max(convVector)  # Find the maximum value in the conversation vector
        if max_value > 0:  # Avoid division by zero
            convVector /= max_value  # Scale the conversation vector so that the maximum value is 1

    return convVector.tolist()  # Convert the numpy array back to a Python list before returning  

