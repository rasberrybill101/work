from fastapi import FastAPI, Query

app = FastAPI()

@app.get("/example")
async def example(param1: str = Query(...), param2: int = Query(...)):
    response = {
        "param1": param1,
        "param2": param2,
        "sum": param1 * param2
    }
    return response

===================================================================
Python fast api POST method that receives a JSON input of the form:
{ "chunk": "this is the input text",
  "history": "these are the previous chunks"
}

from fastapi import FastAPI
from pydantic import BaseModel

class Chunk(BaseModel):
    chunk: str
    history: str

app = FastAPI()

@app.post("/chunks/")
async def create_chunk(chunk: Chunk):
    return chunk


=================================================================
using python create a function "getLastK(k) to return the last k tokens of a space separated string

def getLastK(k, input_string):
    tokens = input_string.split()
    if len(tokens) < k:
        return input_string
    last_k_tokens = tokens[-k:]
    return " ".join(last_k_tokens)

======================== search for reason_level_1 within the conv. ==========
lmplement the following python function in a case-insensitive way:
Given a csv file with columns 
conv_id
complaint_disat
segment_id
call_duration
reason_level_1
reason_level_2
plain_whisper
language_code

Ignore rows where:
column "complaint_disat" has the value "complaint"

column "reason_level_1" has any of the following values:
'*Case ID no Longer in CTR SQL Database'
'*Number did not match case'

create a dictionary of synonyms containing the following words and synonyms
FC, Financial Center
IVR, Automated System
payoff, pay off
payoffs, pay offs
mobile digital, app
write function getSynonym(word) that returns the synonym of a word. For example:
getSynonym('FC') will return 'Financial System'

for each row to be processed:
take the string in reason_level_1 column, replace non-alpha characters such as '(', ')', '/', '-' with a space
ensure that only single spaces are between words
trim the string

Find the first sentence in the plain_whisper column that contains the longest candidate word sequence that can be found in the reason_level_1 column (after all the non-alpha characters in the reason_level_1 column have been replaced with space characters as described previously). In addition, candidate word sequences can be created using synonyms from the dictionary given by "getSynonym()" defined above. For example:
Given reason_level_1 : "Call FC Transfers/Disconnects"
possible sequences are "call FC transfers disconnects", "call financial center transfers disconnects", "call transfers", ...
In this example, the longest sequence in reason_level_1 is "call financial center transfers disconnects". If this substring is found in the "plain_whisper" column, then the sentence that contains the candidate sequence will be selected as the "longest_candidate_sequence" string. Otherwise, search for any other possible identified sequence. If none can be found, then return "No Direct Sequence Found"
Notice that in the example above, 'FC' has a synonym and so it is included in the creation of word sequences.
To be clear, a sentence is defined as a sequence of words terminated by a period (the usual definition of a sentence).

To summarize, the sequence of tokens is initially identified from reason_level_1 tokens and then we search for them in plain_whisper column.
If a sequence is found in "plain_whisper" column, then the sentence that contains the sequence should be returned from the function that has been defined.
For example, in the string:
"it would seem simple. But we know that the quick brown fox jumps over the lazy dog quite quickly indeed. Today is when we find out."
if the sequence to search for is: "jumps over a", then the possible candidate sequences are:
"jumps over a", "jumps over", "over a", "jumps", "over", "a"
then the returned string will be:
"But we know that the quick brown fox jumps over the lazy dog quite quickly indeed"
This is basically the first sentence that contains the longest sub-sequence "jumps over"

complete the processing of all relevant rows before writing the following results to a csv file named "reason_level_1-phrases.txt" which has the following columns:
1) conv-id
2) complaint - if complaint_disat is 'complaint' then write 1 else write 0 in this column
2) reason_level_1
3) plain_whisper
4) sequence - longest candidate sequence from reason_level_1 that was found in the earliest sentence of plain_whisper
5) sentence - this is the sentence that contains the sequence
6) left character position of the returned sentence 
7) right character position of the returned sentence

columns (6) and (7) mark the starting and ending position of the sentence within the 'plain_whisper' text. This is done in order to easily highlight the sentence within the text of 'plain_whisper'.

Make the code modular by breaking it out into multiple smaller functions. It should be easy to port this code over to a jupyter notebook.

========================== sentences from sequencesimport pandas as pd
import csv
import re
from typing import List, Dict, Tuple

# Synonyms Dictionary
synonyms_dict = {
    'FC': 'Financial Center',
    'IVR': 'Automated System',
    'payoff': 'pay off',
    'payoffs': 'pay offs',
    'mobile digital': 'app'
}

ignored_reasons = ['*Case ID no Longer in CTR SQL Database', '*Number did not match case']

def getSynonym(word: str) -> str:
    return synonyms_dict.get(word, word)

def process_row(row: pd.Series) -> Dict[str, str]:
    complaint = 1 if row['complaint_disat'].lower() == 'complaint' else 0
    reason_level_1 = row['reason_level_1']
    plain_whisper = row['plain_whisper']

    # Replace non-alpha characters
    reason_level_1_clean = re.sub(r'[^a-zA-Z0-9 ]', ' ', reason_level_1).strip()

    # Create sequences
    sequences = generate_sequences(reason_level_1_clean, 2)

    # Find sequence and sentence
    sequence, sentence, left_char_pos, right_char_pos = find_sentence(plain_whisper, sequences)

    return {
        'conv_id': row['conv_id'],
        'complaint': complaint,
        'reason_level_1': reason_level_1,
        'plain_whisper': plain_whisper,
        'sequence': sequence,
        'sentence': sentence,
        'left_char_pos': left_char_pos,
        'right_char_pos': right_char_pos,
    }

def generate_sequences(reason_level_1_clean: str, min_length: int) -> List[str]:
    words = reason_level_1_clean.split(' ')
    words = [getSynonym(word) for word in words]
    sequences = [' '.join(words[i: j]) for i in range(len(words)) for j in range(i + 1, len(words) + 1) if len(words[i: j]) >= min_length]
    sequences.sort(key=len, reverse=True)
    return sequences

def find_sentence(plain_whisper: str, sequences: List[str]) -> Tuple[str, str, int, int]:
    sentences = plain_whisper.split('.')
    for sequence in sequences:
        for sentence in sentences:
            if sequence in sentence:
                start = plain_whisper.index(sentence)
                end = start + len(sentence)
                return sequence, sentence, start, end
    return 'No Direct Sequence Found', '', -1, -1

def process_csv(input_file: str, output_file: str):
    # Read CSV
    df = pd.read_csv(input_file)

    # Ignore rows
    df = df[df['complaint_disat'].str.lower() != 'complaint']
    df = df[~df['reason_level_1'].isin(ignored_reasons)]

    results = []

    # Process each row
    for index, row in df.iterrows():
        results.append(process_row(row))

    # Write to CSV
    result_df = pd.DataFrame(results)
    result_df.to_csv(output_file, index=False, quoting=csv.QUOTE_NONNUMERIC)

# Test the code
process_csv('your_input_file.csv', 'reason_level_1-phrases.txt')


