Given two csv files, each with the following structure:
convID - string
label - integer
earliest_detected_transition - integer
token_count - integer
zeros - integer
ones - integer
zerod - integer
oned - integer
spread - float
min_spread - float
max_spread - float
eigen_complaint - float

The first file named "batch_chunking_training.txt" contains training data
The second file named "batch_chunking_testing.txt" contains testing data

In the csv file, only the following columns are to be used to train a neural network:
1) "label" is the expected value and is the desired output
2) "eigen_complaint" is an input value
3) "earliest_detected_transition" is another input value

Based on the 2 input columns, the goal is to predict a label that matches the "label" columns

Write a python implentation that:
takes the training and testing files
creates a neural network
provides Precision, Recall, and accuracy metrics
provides a confusion matrix for the metrics (seaborn would be nice)

============================= implementation 1 =======================
import pandas as pd
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# load data
train_df = pd.read_csv('batch_chunking_training.txt')
test_df = pd.read_csv('batch_chunking_testing.txt')

# select columns
train_data = train_df[['eigen_complaint', 'earliest_detected_transition']]
train_labels = train_df['label']

test_data = test_df[['eigen_complaint', 'earliest_detected_transition']]
test_labels = test_df['label']

# normalize data
train_data = (train_data - train_data.mean()) / train_data.std()
test_data = (test_data - test_data.mean()) / test_data.std()

# build neural network
model = keras.Sequential([
    layers.Dense(64, activation='relu', input_shape=[2]),
    layers.Dense(64, activation='relu'),
    layers.Dense(1, activation='sigmoid'),
])

model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['binary_accuracy'],
)

# train the model
model.fit(
    train_data, train_labels,
    validation_split=0.2,
    batch_size=64,
    epochs=10,
)

# test the model
predictions = model.predict(test_data)
predictions = [1 if p > 0.5 else 0 for p in predictions]

# calculate metrics
precision = precision_score(test_labels, predictions)
recall = recall_score(test_labels, predictions)
accuracy = accuracy_score(test_labels, predictions)

print(f'Precision: {precision}')
print(f'Recall: {recall}')
print(f'Accuracy: {accuracy}')

# generate confusion matrix
matrix = confusion_matrix(test_labels, predictions)

# plot confusion matrix
plt.figure(figsize=(10,7))
sns.heatmap(matrix, annot=True, cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

============================== iteration 2
import pandas as pd
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.model_selection import KFold
from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# load data
train_df = pd.read_csv('batch_chunking_training.txt')
test_df = pd.read_csv('batch_chunking_testing.txt')

# select columns
data = train_df[['eigen_complaint', 'earliest_detected_transition']]
labels = train_df['label']

test_data = test_df[['eigen_complaint', 'earliest_detected_transition']]
test_labels = test_df['label']

# normalize data
data = (data - data.mean()) / data.std()
test_data = (test_data - test_data.mean()) / test_data.std()

# initialize results
acc_scores = []
prec_scores = []
rec_scores = []

# set up k-fold cross-validation
k = 5
kfold = KFold(n_splits=k, shuffle=True)

# iterate over each fold
for train_indices, val_indices in kfold.split(data):
    # generate training data
    train_data = data.iloc[train_indices]
    train_labels = labels.iloc[train_indices]
    
    # generate validation data
    val_data = data.iloc[val_indices]
    val_labels = labels.iloc[val_indices]
    
    # build neural network
    model = keras.Sequential([
        layers.Dense(64, activation='relu', input_shape=[2]),
        layers.Dense(64, activation='relu'),
        layers.Dense(1, activation='sigmoid'),
    ])

    model.compile(
        optimizer='adam',
        loss='binary_crossentropy',
        metrics=['binary_accuracy'],
    )

    # train the model
    model.fit(
        train_data, train_labels,
        validation_data=(val_data, val_labels),
        batch_size=64,
        epochs=10,
        verbose=0  # disable logging for each epoch
    )

    # make predictions on validation set
    predictions = model.predict(val_data)
    predictions = [1 if p > 0.5 else 0 for p in predictions]

    # calculate and save metrics
    acc_scores.append(accuracy_score(val_labels, predictions))
    prec_scores.append(precision_score(val_labels, predictions))
    rec_scores.append(recall_score(val_labels, predictions))

# print average metrics
print(f'Average accuracy: {np.mean(acc_scores)}')
print(f'Average precision: {np.mean(prec_scores)}')
print(f'Average recall: {np.mean(rec_scores)}')

# retrain the model on all the training data
model.fit(
    data, labels,
    batch_size=64,
    epochs=10,
)

# make predictions on the test set using the final model
test_predictions = model.predict(test_data)
test_predictions = [1 if p > 0.5 else 0 for p in test_predictions]

# generate confusion matrix for the test set
matrix = confusion_matrix(test_labels, test_predictions)

# plot confusion matrix
plt.figure(figsize=(10,7))
sns.heatmap(matrix, annot=True, cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

=========================== iteration 3 - Make label categorical
import pandas as pd
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import KFold
from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# load data
train_df = pd.read_csv('batch_chunking_training.txt')
test_df = pd.read_csv('batch_chunking_testing.txt')

# convert integer labels to strings
train_df['ground_truth'] = train_df['ground_truth'].astype(str)
test_df['ground_truth'] = test_df['ground_truth'].astype(str)

# convert string labels to one-hot encoded format
labels = pd.get_dummies(train_df['ground_truth']).values
test_labels = pd.get_dummies(test_df['ground_truth']).values

# select columns
data = train_df[['eigen_complaint', 'earliest_detected_transition', 'volume_of_complaints', 'zerod', 'zeros', 'oned', 'ones']]
test_data = test_df[['eigen_complaint', 'earliest_detected_transition', 'volume_of_complaints', 'zerod', 'zeros', 'oned', 'ones']]

# normalize data
data = (data - data.mean()) / data.std()
test_data = (test_data - test_data.mean()) / test_data.std()

# initialize results
acc_scores = []
prec_scores = []
rec_scores = []

# set up k-fold cross-validation
k = 5
kfold = KFold(n_splits=k, shuffle=True)

# iterate over each fold
for train_indices, val_indices in kfold.split(data):
    # generate training data
    train_data = data.iloc[train_indices]
    train_labels = labels[train_indices]
    
    # generate validation data
    val_data = data.iloc[val_indices]
    val_labels = labels[val_indices]
    
    # build neural network
    model = keras.Sequential([
        layers.Dense(64, activation='relu', input_shape=[2]),
        layers.Dense(64, activation='relu'),
        layers.Dense(2, activation='softmax'),
    ])

    model.compile(
        optimizer='adam',
        loss='categorical_crossentropy',
        metrics=['accuracy'],
    )

    # train the model
    model.fit(
        train_data, train_labels,
        validation_data=(val_data, val_labels),
        batch_size=64,
        epochs=10,
        verbose=0
    )

    # make predictions on validation set
    predictions = np.argmax(model.predict(val_data), axis=-1)

    # calculate and save metrics
    acc_scores.append(accuracy_score(np.argmax(val_labels, axis=-1), predictions))
    prec_scores.append(precision_score(np.argmax(val_labels, axis=-1), predictions, average='weighted'))
    rec_scores.append(recall_score(np.argmax(val_labels, axis=-1), predictions, average='weighted'))

# print average metrics
print(f'Average accuracy: {np.mean(acc_scores)}')
print(f'Average precision: {np.mean(prec_scores)}')
print(f'Average recall: {np.mean(rec_scores)}')

# retrain the model on all the training data
model.fit(
    data, labels,
    batch_size=64,
    epochs=10,
)
# save the model
model.save('batch_chunking_model.h5')

# make predictions on the test set using the final model
test_predictions = np.argmax(model.predict(test_data), axis=-1)

# generate confusion matrix for the test set
matrix = confusion_matrix(np.argmax(test_labels, axis=-1), test_predictions)

# plot confusion matrix
plt.figure(figsize=(10,7))
sns.heatmap(matrix, annot=True, fmt='d')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

================================= iteration 4 - logistic regression
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# load data
train_df = pd.read_csv('batch_chunking_training.txt')
test_df = pd.read_csv('batch_chunking_testing.txt')

# convert integer labels to strings
train_df['label'] = train_df['label'].astype(str)
test_df['label'] = test_df['label'].astype(str)

# select columns
data = train_df[['eigen_complaint', 'earliest_detected_transition']]
labels = train_df['label']

test_data = test_df[['eigen_complaint', 'earliest_detected_transition']]
test_labels = test_df['label']

# create logistic regression model
model = LogisticRegression()

# fit model
model.fit(data, labels)

# make predictions
predictions = model.predict(test_data)

# calculate metrics
accuracy = accuracy_score(test_labels, predictions)
precision = precision_score(test_labels, predictions, pos_label='1')
recall = recall_score(test_labels, predictions, pos_label='1')

# print metrics
print(f'Accuracy: {accuracy}')
print(f'Precision: {precision}')
print(f'Recall: {recall}')

# generate confusion matrix
matrix = confusion_matrix(test_labels, predictions)

# plot confusion matrix
plt.figure(figsize=(10,7))
sns.heatmap(matrix, annot=True, fmt='d')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

============================ report final metrics# ... previous code ...

final_fold = list(kf.split(data))[-1]
for i, (train_index, test_index) in enumerate(kf.split(data)):
    # split data
    X_train, X_test = data.iloc[train_index], data.iloc[test_index]
    y_train, y_test = labels[train_index], labels[test_index]
    
    # ... build, compile, and fit model ...

    # On the last fold, calculate and print metrics
    if (train_index, test_index) == final_fold:
        # make predictions
        predictions = model.predict_classes(X_test)

        # calculate metrics
        accuracy = accuracy_score(np.argmax(y_test, axis=1), predictions)
        precision = precision_score(np.argmax(y_test, axis=1), predictions, pos_label=1)
        recall = recall_score(np.argmax(y_test, axis=1), predictions, pos_label=1)

        # print metrics
        print(f'Accuracy: {accuracy}')
        print(f'Precision: {precision}')
        print(f'Recall: {recall}')

======================================== heatmap blue/red

# ... previous code ...

from matplotlib.colors import LinearSegmentedColormap

# Define a colormap
cmap = LinearSegmentedColormap.from_list("Custom", ["red", "blue"], N=2)

# Create confusion matrix
cm = confusion_matrix(y_true, y_pred)

# Plot confusion matrix
sns.heatmap(cm, annot=True, fmt='d', cmap=cmap)
plt.show()

=========================== metrics 
Instead of this:
    # calculate and save metrics
    accuracy = accuracy_score(y_test, predictions)
    precision = precision_score(y_test, predictions, pos_label='1')
    recall = recall_score(y_test, predictions, pos_label='1')
    
    accuracy_list.append(accuracy)
    precision_list.append(precision)
    recall_list.append(recall)

# print metrics
print(f'Average Accuracy: {np.mean(accuracy_list)}')
print(f'Average Precision: {np.mean(precision_list

I just want to see the very latest set of metrics at the end of training
I do not want the average.

can you suggest replacement code for the above

# ... previous code ...

# On the last fold, calculate and print metrics
if i == n_splits - 1:
    # make predictions
    predictions = model.predict_classes(X_test)

    # calculate metrics
    accuracy = accuracy_score(np.argmax(y_test, axis=1), predictions)
    precision = precision_score(np.argmax(y_test, axis=1), predictions, pos_label=1)
    recall = recall_score(np.argmax(y_test, axis=1), predictions, pos_label=1)

    # print metrics
    print(f'Accuracy: {accuracy}')
    print(f'Precision: {precision}')
    print(f'Recall: {recall}')
	
========================== saving, retrieving, and running the model
# Assuming a Keras model named 'model'
model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'

from keras.models import load_model
# Returns a compiled model identical to the previous one
model = load_model('my_model.h5')

# Once loaded, model can be used to make predictions
predictions = model.predict(new_data)

============================ get metrics by running a saved model against a data set
Using Python. Given a model saved to file 'batch_chunking_model.h5', read in the model and
use it to make predictions on some test data in a csv file called 'batch_chunking_testing.txt' that has the following structure:
convID - string
ground_truth - integer
earliest_detected_transition - integer
volume_of_complaints - integer
zeros - integer
ones - integer
zerod - float
oned - float
spread - float
min_spread - float
max_spread - float
eigen_complaint - float

For each line in the input file, the model take the following columns as inputs:
eigen_complaint
earliest_detected_transition
volume_of_complaints
zerod
zeros
oned
ones

The order of the inputs above matches the order of inputs during training of the model

The model should return a prediction of either 0 or 1 ('0' or '1'). The goal is to compare
the output of the model with the 'ground_truth' column.

Once all predictions are done, report the following metrics:

Accuracy
Precision
Recall
Confusion Matrix

Also create a Plot of the confusion matrix using a light to dark blue tone

------

import pandas as pd
import numpy as np
from tensorflow.keras.models import load_model
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
model = load_model('batch_chunking_model.h5')

# Load the test data
df = pd.read_csv('batch_chunking_testing.txt')

# Prepare the test data for prediction
test_data = df[['eigen_complaint', 'earliest_detected_transition', 'volume_of_complaints', 'zerod', 'zeros', 'oned', 'ones']]

# Make predictions
predictions = model.predict(test_data)
predictions = [1 if pred >= 0.5 else 0 for pred in predictions]  # Threshold at 0.5

# Calculate metrics
accuracy = accuracy_score(df['ground_truth'], predictions)
precision = precision_score(df['ground_truth'], predictions)
recall = recall_score(df['ground_truth'], predictions)
conf_matrix = confusion_matrix(df['ground_truth'], predictions)

# Print metrics
print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")
print("Confusion Matrix:")
print(conf_matrix)

# Plot confusion matrix
plt.figure(figsize=(10,7))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Model Prediction')
plt.ylabel('Ground Truth')
plt.show()

This error happens when trying to run the code:
ValueError at this line: 
predictions = [1 if pred >= 0.5 else 0 for pred in predictions]  # Threshold at 0.5

ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()

Also, when the model was trained, a one-hot encoding was used like this ...
# convert integer labels to strings
train_df['ground_truth'] = train_df['ground_truth'].astype(str)
test_df['ground_truth'] = test_df['ground_truth'].astype(str)

# convert string labels to one-hot encoded format
labels = pd.get_dummies(train_df['ground_truth']).values
test_labels = pd.get_dummies(test_df['ground_truth']).values

------
import pandas as pd
import numpy as np
from tensorflow.keras.models import load_model
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
dir = 'chunk_test_data/'
model = load_model(dir + 'batch_chunking_model.h5')

# Load the test data
df = pd.read_csv(dir + 'batch_chunking_testing.txt')

# Prepare the test data for prediction
test_data = df[['eigen_complaint', 'earliest_detected_transition', 'volume_of_complaints', 'zerod', 'zeros', 'oned', 'ones']]

# Make predictions
predictions = model.predict(test_data)
predictions = np.argmax(predictions, axis=1)  # Convert from one-hot to labels

# Convert ground truth from one-hot to labels
ground_truth = np.argmax(df[['0', '1']].values, axis=1)

# Calculate metrics
accuracy = accuracy_score(ground_truth, predictions)
precision = precision_score(ground_truth, predictions)
recall = recall_score(ground_truth, predictions)
conf_matrix = confusion_matrix(ground_truth, predictions)

# Print metrics
print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")
print("Confusion Matrix:")
print(conf_matrix)

# Plot confusion matrix
plt.figure(figsize=(10,7))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Truth')
plt.show()

----------------------------------
To avoid any confusion, this is the code that was used to train and save the model:
import pandas as pd
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import KFold
from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# load data
train_df = pd.read_csv('batch_chunking_training.txt')
test_df = pd.read_csv('batch_chunking_testing.txt')

# convert integer labels to strings
train_df['ground_truth'] = train_df['ground_truth'].astype(str)
test_df['ground_truth'] = test_df['ground_truth'].astype(str)

# convert string labels to one-hot encoded format
labels = pd.get_dummies(train_df['ground_truth']).values
test_labels = pd.get_dummies(test_df['ground_truth']).values

# select columns
data = train_df[['eigen_complaint', 'earliest_detected_transition', 'volume_of_complaints', 'zerod', 'zeros', 'oned', 'ones']]
test_data = test_df[['eigen_complaint', 'earliest_detected_transition', 'volume_of_complaints', 'zerod', 'zeros', 'oned', 'ones']]

# normalize data
data = (data - data.mean()) / data.std()
test_data = (test_data - test_data.mean()) / test_data.std()

# initialize results
acc_scores = []
prec_scores = []
rec_scores = []

# set up k-fold cross-validation
k = 5
kfold = KFold(n_splits=k, shuffle=True)

# iterate over each fold
for train_indices, val_indices in kfold.split(data):
    # generate training data
    train_data = data.iloc[train_indices]
    train_labels = labels[train_indices]
    
    # generate validation data
    val_data = data.iloc[val_indices]
    val_labels = labels[val_indices]
    
    # build neural network
    model = keras.Sequential([
        layers.Dense(64, activation='relu', input_shape=[2]),
        layers.Dense(64, activation='relu'),
        layers.Dense(2, activation='softmax'),
    ])

    model.compile(
        optimizer='adam',
        loss='categorical_crossentropy',
        metrics=['accuracy'],
    )

    # train the model
    model.fit(
        train_data, train_labels,
        validation_data=(val_data, val_labels),
        batch_size=64,
        epochs=10,
        verbose=0
    )

    # make predictions on validation set
    predictions = np.argmax(model.predict(val_data), axis=-1)

    # calculate and save metrics
    acc_scores.append(accuracy_score(np.argmax(val_labels, axis=-1), predictions))
    prec_scores.append(precision_score(np.argmax(val_labels, axis=-1), predictions, average='weighted'))
    rec_scores.append(recall_score(np.argmax(val_labels, axis=-1), predictions, average='weighted'))

# print average metrics
print(f'Average accuracy: {np.mean(acc_scores)}')
print(f'Average precision: {np.mean(prec_scores)}')
print(f'Average recall: {np.mean(rec_scores)}')

# retrain the model on all the training data
model.fit(
    data, labels,
    batch_size=64,
    epochs=10,
)
# save the model
model.save('batch_chunking_model.h5')

# make predictions on the test set using the final model
test_predictions = np.argmax(model.predict(test_data), axis=-1)

# generate confusion matrix for the test set
matrix = confusion_matrix(np.argmax(test_labels, axis=-1), test_predictions)

# plot confusion matrix
plt.figure(figsize=(10,7))
sns.heatmap(matrix, annot=True, fmt='d')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

Based on this code, and given the model saved to file 'batch_chunking_model.h5', read in the model and
use it to make predictions on some test data in a csv file called 'batch_chunking_testing.txt' that has the following structure:
convID - string
ground_truth - integer
earliest_detected_transition - integer
volume_of_complaints - integer
zeros - integer
ones - integer
zerod - float
oned - float
spread - float
min_spread - float
max_spread - float
eigen_complaint - float

For each line in the input file, the model take the following columns as inputs:
eigen_complaint
earliest_detected_transition
volume_of_complaints
zerod
zeros
oned
ones

The order of the inputs above matches the order of inputs during training of the model

The model should return a prediction of either 0 or 1 ('0' or '1'). The goal is to compare
the output of the model with the 'ground_truth' column.

Once all predictions are done, report the following metrics:

Accuracy
Precision
Recall
Confusion Matrix

Also create a Plot of the confusion matrix using a light to dark blue tone

---------------
import pandas as pd
import numpy as np
from tensorflow.keras.models import load_model
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Load the saved model
model = load_model('batch_chunking_model.h5')

# Load the test data
df = pd.read_csv('batch_chunking_testing.txt')

# Convert integer labels to string (as done in training)
df['ground_truth'] = df['ground_truth'].astype(str)

# Convert string labels to one-hot encoded format
test_labels = pd.get_dummies(df['ground_truth']).values

# Prepare the test data for prediction
test_data = df[['eigen_complaint', 'earliest_detected_transition', 'volume_of_complaints', 'zerod', 'zeros', 'oned', 'ones']]

# Normalize data as done in training
test_data = (test_data - test_data.mean()) / test_data.std()

# Make predictions
predictions = model.predict(test_data)
predictions = np.argmax(predictions, axis=1)  # Convert from one-hot to labels

# Convert ground truth from one-hot to labels
ground_truth = np.argmax(test_labels, axis=1)

# Calculate metrics
accuracy = accuracy_score(ground_truth, predictions)
precision = precision_score(ground_truth, predictions)
recall = recall_score(ground_truth, predictions)
conf_matrix = confusion_matrix(ground_truth, predictions)

# Print metrics
print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")
print("Confusion Matrix:")
print(conf_matrix)

# Plot confusion matrix
plt.figure(figsize=(10,7))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Truth')
plt.show()

==================== save best model ...........
import pandas as pd
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import KFold
from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# load data
dir = 'chunk_test_data/'
train_df = pd.read_csv(dir + 'batch_chunking_training.txt')
test_df = pd.read_csv(dir + 'batch_chunking_testing.txt')

# convert integer labels to strings
train_df['ground_truth'] = train_df['ground_truth'].astype(str)
test_df['ground_truth'] = test_df['ground_truth'].astype(str)

# convert string labels to one-hot encoded format
labels = pd.get_dummies(train_df['ground_truth']).values
test_labels = pd.get_dummies(test_df['ground_truth']).values

# select columns
data = train_df[['eigen_complaint', 'earliest_detected_transition', 'volume_of_complaints', 'zerod', 'zeros', 'oned', 'ones']]
test_data = test_df[['eigen_complaint', 'earliest_detected_transition', 'volume_of_complaints', 'zerod', 'zeros', 'oned', 'ones']]

# normalize data
data = (data - data.mean()) / data.std()
test_data = (test_data - test_data.mean()) / test_data.std()

# set up k-fold cross-validation
k = 5
kfold = KFold(n_splits=k, shuffle=True)

best_model_path = dir + "best_model.h5"
best_accuracy = 0.0

for train_indices, val_indices in kfold.split(data):
    # generate training data
    train_data = data.iloc[train_indices]
    train_labels = labels[train_indices]
    
    # generate validation data
    val_data = data.iloc[val_indices]
    val_labels = labels[val_indices]
    
    # build neural network
    model = keras.Sequential([
        layers.Dense(64, activation='relu', input_shape=[7]),
        layers.Dense(64, activation='relu'),
        layers.Dense(2, activation='softmax'),
    ])

    model.compile(
        optimizer='adam',
        loss='categorical_crossentropy',
        metrics=['accuracy'],
    )

    # Create a callback that saves the model's weights whenever validation accuracy improves
    checkpoint_cb = ModelCheckpoint(best_model_path, monitor='val_accuracy', save_best_only=True, mode='max')

    # train the model
    history = model.fit(
        train_data, train_labels,
        validation_data=(val_data, val_labels),
        batch_size=64,
        epochs=10,
        verbose=0,
        callbacks=[checkpoint_cb]
    )

    # Check if this model's maximum validation accuracy is better than the current best
    max_val_accuracy = np.max(history.history['val_accuracy'])
    if max_val_accuracy > best_accuracy:
        best_accuracy = max_val_accuracy

# Load the best model
best_model = keras.models.load_model(best_model_path)

# make predictions on the test set using the best model
test_predictions = np.argmax(best_model.predict(test_data), axis=-1)

# generate confusion matrix for the test set
matrix = confusion_matrix(np.argmax(test_labels, axis=-1), test_predictions)

# plot confusion matrix
plt.figure(figsize=(10,7))
sns.heatmap(matrix, annot=True, fmt='d')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()