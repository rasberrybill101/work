Given 2 data files:
(1) Tab separated file1 (named "train_data_12_42_cumulative.csv") with the following columns:
frame, label, chunkStart, chunkEnd, voiceFilename
label is an integer
expected in an integer
chunkStart is an integer
chunkEnd is an integer
voiceFilename is a string that acts as the primary key for the row

Each row in file1 (with primary key "voiceFilename")columns:
"chunkStart" is the position of the first token in "frame" column  
"chunkEnd" is the position of the last token in "frame" column

The value of the "voiceFilename" column in the rows of file1 is equal to the value of the convID column in file2 rows.


(2) Comma separated file2 (named "train_data_12_42_cumulative_bert_final_metrics.txt") with the following columns:
convID, 1, 2, 3, 4, 5, 6, 7, ....., 42
convID is a string that acts as the primary key for the row
The remaining columns in each row are integers 1 through 42, separated by commas.

Data in columns "1" through "42" can take one of the following five values:
"TP", "TN", "FP", "FN", "--"

The following functionality is required
1. function getTokensFromRow(chunkSize = 12)
For any row in file2 that contain "TP" in columns "1" through "42" :
   set the location of the first TP in the row as "firstTPLocation"
   set the location of the the last "TP" that is contiguous to the first TP in this row to "lastTPLocation"
   Two TPs are contiguous (or form a contiguous chain) if there are only other "TP"s between them.For example:
    "TP", "TP", "TP", "TP" is a contiguous chain
	but "TP", "TP", "FN", "TP" is not a contiguous chain since all the TPs are not right next to each other.
	Rather, only first 2 TPs are contiguous. The position of the first one will be "firstTPLocation", and the position of the last TP in the contiguous chain will "lastTPLocation"
	
	Then, given "firstTPLocation", and "lastTPLocation", the task is to return the tokens between position 12*(firstTPLocation - 1) and 12*(lastTPLocation) in column "frame" of file1 for the last row whose voiceFilename is equal to convID of the current row in file2. This will be the row in file1 that has the most tokens present in "frame" column (the longest string). 12 is the chunkSize.
	
	The tokens (and therefore their positions) in the "frame" column of file1 are obtained by space separating the string of "frame". The first token will be at position 1, the second token at position 2, etc.
	
	The function should return the string obtained by concatenation of the tokens (using space character separation) between "firstTPLocation" and "lastTPLocation" in "frame" column.


2. function getCandidates(chunkSize = 12) 
The function getCandidates() should return a list of strings for the eligible rows in file2, each string being the result of a call to getTokensFromRow(chunkSize=12) should be called for each row in file2, but only rows with "TP" in columns "1" through "42" of file2 should return tokens.

The list of strings obtained from getCandidates() should be saved to file3 (named "train_data_augmentation.txt") that has the following columns (tab separated) for each string in the list:

convID - the primary key of the row (same as in file2)
candidate - string from the list



#===================================================================
# get candidate training utterances
#===================================================================

import pandas as pd

def getTokensFromRow(row, df1, chunkSize=12):
    firstTPLocation = -1
    lastTPLocation = -1
    for i in range(1, 43):
        if row[str(i)] == 'TP':
            if firstTPLocation == -1:
                firstTPLocation = i
            lastTPLocation = i
        elif firstTPLocation != -1:
            break

    if firstTPLocation != -1:
        voiceFilename = row['convID']
        frame_row = df1[df1['voiceFilename'] == voiceFilename]
        frame_str = frame_row['frame'].values[0]
        frame_tokens = frame_str.split(' ')
        tokens_to_return = frame_tokens[chunkSize*(firstTPLocation - 1):chunkSize*lastTPLocation]
        return ' '.join(tokens_to_return)
    return ''

def getCandidates(filename1, filename2, chunkSize=12):
    df1 = pd.read_csv(filename1, sep='\t')
    df2 = pd.read_csv(filename2)
    
    candidates = []
    for index, row in df2.iterrows():
        tokens = getTokensFromRow(row, chunkSize, df1)
        if tokens:
            candidates.append([row['convID'], tokens])
    return candidates

def saveCandidatesToFile(candidates, filename):
    df = pd.DataFrame(candidates, columns=['convID', 'candidate'])
    df.to_csv(filename, sep='\t', index=False)

dir = '/chunk-complaint/chunk_test_data/'
filename1 = dir + 'train_data_12_42_cumulative.csv'
filename2 = dir + 'train_data_12_42_cumulative_bert_predicted_final_metrics.txt'
filename3 = dir + 'train_data_augmentation.txt'
candidates = getCandidates(filename1, filename2)
saveCandidatesToFile(candidates, filename3)

--------------------------------------- need to fix:

No. This is an incorrect interpretation. You are to use the existing order of rows in file1. The order of rows in file1 is already ordering the rows by length of the "frame" column (increasing order). If you want to re-order, then you should re-order by decreasing length of "frame" column so that the desired row for each filename becomes the first occurrence of that filename among the multiple occurrences of filename. Let me know if you need further clarification. Here is the entire specification again with the update :

Given 2 data files:
(1) Tab separated file1 (named "train_data_12_42_cumulative.csv") with the following columns:
frame, label, chunkStart, chunkEnd, voiceFilename
label is an integer
chunkStart is an integer
chunkEnd is an integer
voiceFilename is a string that acts as the primary key for the row

Each row in file1 (with primary key "voiceFilename")columns:
"chunkStart" is the position of the first token in "frame" column  
"chunkEnd" is the position of the last token in "frame" column

The value of the "voiceFilename" column in the rows of file1 is equal to the value of the convID column in file2 rows.


(2) Comma separated file2 (named "train_data_12_42_cumulative_bert_final_metrics.txt") with the following columns:
convID, 1, 2, 3, 4, 5, 6, 7, ....., 42
convID is a string that acts as the primary key for the row
The remaining columns in each row are integers 1 through 42, separated by commas.

Data in columns "1" through "42" can take one of the following five values:
"TP", "TN", "FP", "FN", "--"

The following functionality is required
1. function getTokensFromRow(chunkSize = 12)
For any row in file2 that contain "TP" in columns "1" through "42" :
   set the location of the first TP in the row as "firstTPLocation"
   set the location of the the last "TP" that is contiguous to the first TP in this row to "lastTPLocation"
   Two TPs are contiguous (or form a contiguous chain) if there are only other "TP"s between them.For example:
    "TP", "TP", "TP", "TP" is a contiguous chain
	but "TP", "TP", "FN", "TP" is not a contiguous chain since all the TPs are not right next to each other.
	Rather, only first 2 TPs are contiguous. The position of the first one will be "firstTPLocation", and the position of the last TP in the contiguous chain will "lastTPLocation"
	
	Then, given "firstTPLocation", and "lastTPLocation", the task is to return the tokens between position 12*(firstTPLocation - 1) and 12*(lastTPLocation) in column "frame" of file1 for the last row whose voiceFilename is equal to convID of the current row in file2. This will be the row in file1 that has the most tokens present in "frame" column (the longest string). 12 is the chunkSize.
	
	The tokens (and therefore their positions) in the "frame" column of file1 are obtained by space separating the string of "frame". The first token will be at position 1, the second token at position 2, etc.
	
	The function should return the string obtained by concatenation of the tokens (using space character separation) between "firstTPLocation" and "lastTPLocation" in "frame" column.


2. function getCandidates(chunkSize = 12) 
The function getCandidates() should return a list of strings for the eligible rows in file2, each string being the result of a call to getTokensFromRow(chunkSize=12) should be called for each row in file2, but only rows with "TP" in columns "1" through "42" of file2 should return tokens.

The list of strings obtained from getCandidates() should be saved to file3 (named "train_data_augmentation.txt") that has the following columns (tab separated) for each string in the list:

convID - the primary key of the row (same as in file2)
candidate - string from the list


#===================================================================
# get candidate training utterances
#===================================================================
import pandas as pd

def getTokensFromRow(row, df1, chunkSize=12):
    firstTPLocation = -1
    lastTPLocation = -1
    for i in range(1, 43):
        if row[str(i)] == 'TP':
            if firstTPLocation == -1:
                firstTPLocation = i
            lastTPLocation = i
        elif firstTPLocation != -1:
            break

    if firstTPLocation != -1:
        voiceFilename = row['convID']
        frame_row = df1[df1['voiceFilename'] == voiceFilename]
        if not frame_row.empty:
            max_len_idx = frame_row['frame'].str.split().str.len().idxmax()
            frame_row = frame_row.loc[max_len_idx]
            frame_str = frame_row['frame']
            frame_tokens = frame_str.split(' ')
            tokens_to_return = frame_tokens[chunkSize*(firstTPLocation - 1):chunkSize*lastTPLocation]
            return ' '.join(tokens_to_return)
    return ''

def getCandidates(filename1, filename2, chunkSize=12):
    df1 = pd.read_csv(filename1, sep='\t')
    df2 = pd.read_csv(filename2)
    
    candidates = []
    for index, row in df2.iterrows():
        tokens = getTokensFromRow(row, df1, chunkSize)
        if tokens:
            candidates.append([row['convID'], tokens])
    return candidates

def saveCandidatesToFile(candidates, filename):
    df = pd.DataFrame(candidates, columns=['convID', 'candidate'])
    df.to_csv(filename, sep='\t', index=False)

dir = '/chunk-complaint/chunk_test_data/'
filename1 = dir + 'train_data_12_42_cumulative.csv'
filename2 = dir + 'train_data_12_42_cumulative_bert_predicted_final_metrics.txt'
filename3 = dir + 'train_data_augmentation.txt'
candidates = getCandidates(filename1, filename2)
saveCandidatesToFile(candidates, filename3)

============================================= modification:

Include the column 'label' from file1 to the final candidates that will be written in "saveCandidatesToFile".
Also include the length of each list of tokens,

============================================= Additional requirement
Supposing we want to limit the number of returned tokens such that no more than a certain number "tokenLimit" is returned from     tokens_to_return = frame_tokens[chunkSize*(firstTPLocation - 1):chunkSize*lastTPLocation]
rewrite  getTokensFromRow(row, df1, chunkSize=12) by adding an arg "tokenLimit" with an initial value of -1 (which means no limit). Any positive integer value for tokenLimit means return no more than tokenLimit tokens. If total number of tokens is less, then return the lower number.

=============================================
import pandas as pd

def getTokensFromRow(row, df1, chunkSize=12, tokenLimit=-1):
    firstTPLocation = -1
    lastTPLocation = -1
    for i in range(1, 43):
        if row[str(i)] == 'TP':
            if firstTPLocation == -1:
                firstTPLocation = i
            lastTPLocation = i
        elif firstTPLocation != -1:
            break

    if firstTPLocation != -1:
        voiceFilename = row['convID']
        frame_row = df1[df1['voiceFilename'] == voiceFilename]
        max_len_idx = frame_row['frame'].str.split().str.len().idxmax()
        frame_row = frame_row.loc[max_len_idx]
        frame_str = frame_row['frame']
        frame_tokens = frame_str.split(' ')
        tokens_to_return = frame_tokens[chunkSize*(firstTPLocation - 1):chunkSize*lastTPLocation]

        # Apply token limit if applicable
        if tokenLimit > 0 and len(tokens_to_return) > tokenLimit:
            tokens_to_return = tokens_to_return[:tokenLimit]
        
        numTokens = len(tokens_to_return)

        return numTokens, frame_row['label'], ' '.join(tokens_to_return)
    return 0, '', ''

def getCandidates(filename1, filename2, chunkSize=12):
    df1 = pd.read_csv(filename1, sep='\t')
    df2 = pd.read_csv(filename2)
    
    candidates = []
    for index, row in df2.iterrows():
        numTokens, label, tokens = getTokensFromRow(row, df1, chunkSize)
        if tokens:
            candidates.append([row['convID'], label, numTokens, tokens])
    return candidates

def saveCandidatesToFile(candidates, filename):
    df = pd.DataFrame(candidates, columns=['convID', 'label', 'numTokens', 'candidate'])
    df.to_csv(filename, sep='\t', index=False)

dir = '/chunk-complaint/chunk_test_data/'
filename1 = dir + 'train_data_12_42_cumulative.csv'
filename2 = dir + 'train_data_12_42_cumulative_bert_predicted_final_metrics.txt'
filename3 = dir + 'train_data_augmentation.txt'
candidates = getCandidates(filename1, filename2)
saveCandidatesToFile(candidates, filename3)

================================================ plot histogram of string lengths

Define the function showCandidateLengths() which will plot a barchart or histogram of the numTokens in each candidate (x-axis) vs how many candidates have such a length (y-axis). Basically, show a frequency distribution of the number of tokens in each candidate.

================================================ Implementation:

import matplotlib.pyplot as plt

def showCandidateLengths(candidates):
    numTokens = [candidate[2] for candidate in candidates]
    plt.hist(numTokens, bins=range(min(numTokens), max(numTokens) + 1), alpha=0.7, edgecolor='black')
    plt.title('Number of tokens in each candidate')
    plt.xlabel('Number of tokens')
    plt.ylabel('Number of candidates')
    plt.show()

================================================= usage:
dir = '/chunk-complaint/chunk_test_data/'
filename1 = dir + 'train_data_12_42_cumulative.csv'
filename2 = dir + 'train_data_12_42_cumulative_bert_predicted_final_metrics.txt'
filename3 = dir + 'train_data_augmentation.txt'
candidates = getCandidates(filename1, filename2)
saveCandidatesToFile(candidates, filename3)
showCandidateLengths(candidates)


------------------------------- implementation (update the function getTokensFromRow: stop at sentence boundaries

write a function "getCompleteSentences(inputText, keepStart='True')" that takes as input a piece of text, and returns only complete complete sentences from one or both ends of the input text. That means that the very first token should now be the one that follows the first period and the very last token should be the one that has the last period. For example, if the inputText  is:
 inputText = "end part of prev sentence. this becomes the first selected sentence. here is the second. partial part of next"

Calling getCompleteSentences(text, keepStart='False') will return:
"this becomes the selected sentence. here is the second."

Calling getCompleteSentences(text, keepStart='True') will return:
"end part of prev sentence. this becomes the first selected sentence. here is the second.

Thus, any partial final sentence is removed if "keepStart='True'", but everything at the beginning of
Both the initial and final partial sentences are removed if "keepStart='False'".

The only exception to removal of the final portion of text is if it terminates with a period.

#=============================================================================
# return complete sentences for augmentation
#=============================================================================

def getCompleteSentences(inputText, keepStart=True):
    # Remove leading and trailing spaces
    inputText = inputText.strip()

    # Save the information whether the text ends with a period
    endsWithPeriod = inputText.endswith('.')
    
    # Split the input text into sentences based on the period
    sentences = inputText.split('.')
    
    # Remove the first sentence if it is not complete and keepStart is False
    if len(sentences) > 1 and not keepStart:
        sentences.pop(0)
    
    # Remove the last sentence if it is not complete (i.e., inputText does not end with a period)
    if len(sentences) > 1 and not endsWithPeriod:
        sentences.pop(-1)

    # Combine the sentences back into a single string
    outputText = '.'.join(sentences)

    # Add the period at the end if the input text had it
    if endsWithPeriod and outputText:
        outputText += '.'

    # Remove leading and trailing spaces
    outputText = outputText.strip()

    return outputText