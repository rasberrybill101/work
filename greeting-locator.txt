========================== get greeting sentences ===============
Given a tab-separated file "train_data_v3_metadata.tsv" with columns: 
conv_id
label
call_duration
reason_level_1
reason_level_2
plain_whisper

Write a function "find_greeting(conversation: str, greeting_phrases: List[str])" that will return the text from the beginning of the string "conversation" until the 2 sentences (configurable as next_k) after a phrase in the specified list of greeting phrases

"getGreeting()" should look in "conversation" for the first occurrence of any of the phrases in the list of greeting_phrases (which will be specified below). Once the phrase is found, the function should return all the text from the beginning of "conversation" to the the of the next k (next_k) sentences that immediately follows the sentence that contains the phrase.

Here is the list of greeting_phrases:
    greeting_phrases = [
        "how can I help",
        "how may I help you today",
        "how can I help you today",
        "what can I do for you",
        "what can I do for you today",
        "what may I do for you today",
        "how can I assist you today",
        "how can I be of assistance ... today",
        "I will be able to assist ... today",
        "how can I provide you ... today",
        "how may I help you in today's call",
        "how may I ... you today",
        "how can I ... you today",
        "the pleasure of speaking with today",
        "calling in here today",
        "waiting to speak ... today",
        "can I have your name",
        "may I have your name"
    ]

The ellipsis ... means up to 4 words. For instance:
"how can I ... you today" can match any of the following:
"how can I be of service to you today"
"how can I provide service to you today"
"how can I help you today"
etc.

We will be looking for the last occurrence of the introductory sentence, and then fetch the next k sentences (where k is an argument to the extraction function).

A sentence is defined according to the following function:
def extract_sentences(text):
    sentences = re.split(r'(?<!\w\.\w.)(?<![A-Z][a-z]\.)(?<=\.(?!\d)|\?|!)\s', text)
    return sentences

when searching for a sentence in "conversation" that matches the phrase, use case-insensitive comparison and discard punctuations such as commas and periods in order to improve the chances of a match.

Write function "save_greetings(inputFile: str = "train_data_v3_metadata.tsv", outputFile: str)", by applying the function getGreeting defined above to the text from the "plain_whisper" column of each line from the file train_data_v3_metadata.tsv and write the results to another file "conv_greetings.txt" using the tab separated columns:
conv_id
greeting_text

#%%
#====================================================================================
# Locate greeting sentences
#====================================================================================
import re
import csv
from typing import List

# Precompile the regular expression for sentence splitting
sentence_re = re.compile(r'(?<!\w\.\w.)(?<![A-Z][a-z]\.)(?<=\.(?!\d)|\?|!)\s')

def extract_sentences(text):
    sentences = sentence_re.split(text)
    return sentences

def getFirstN(conversation: str, n: int) -> str:
    sentences = extract_sentences(conversation)
    return " ".join(sentences[:n])

def getPhrases():
    greeting_phrases = [
        "(how|what) \w+ I (\w+\s){0,5}you(\s+\w+)?(today| tonight)?",
        "I will (\w+\s+) assist you( today)?",
        "how (could|may|can) I (\w+\s){0,5}today('s)?( call)?",
        "the pleasure of speaking with today",
        "calling in here today",
        "waiting to speak (\w+\s){0,5}today",
        "(could|can|may) I have your name"
    ]
    return greeting_phrases

def find_greeting(conversation: str, conv_id: str, greeting_phrases: List[str], next_k: int = 0, first_n: int = 6) -> (str, str):
    sentences = extract_sentences(conversation)

    greeting_text = ""
    missing_match = None
    # Only consider the first 25 sentences
    for i, sentence in enumerate(sentences[:25]):
        # Normalize the sentence (remove punctuation and convert to lowercase)
        normalized_sentence = re.sub(r'[^\w\s]', '', sentence.lower())
        for gp in greeting_phrases:
            # Normalize the greeting phrase (remove punctuation and convert to lowercase)
            if re.search(gp.lower(), normalized_sentence):
                greeting_text = " ".join(sentences[:i + next_k + 1])
                break
            else:
                missing_match = conv_id + '\t' + getFirstN(conversation, first_n) + '\n'
        if greeting_text:
            break
    return greeting_text, missing_match

def one_shot(text):
    greeting_phrases = getPhrases()
    greeting_text = ""
    missing_match = None
    # Only consider the first 25 sentences
    for i, sentence in enumerate(sentences[:25]):
        # Normalize the sentence (remove punctuation and convert to lowercase)
        normalized_sentence = re.sub(r'[^\w\s]', '', sentence.lower())
        for gp in greeting_phrases:
            # Normalize the greeting phrase (remove punctuation and convert to lowercase)
            if re.search(gp.lower(), normalized_sentence):
                greeting_text = " ".join(sentences[:i + 1])
                
def save_greetings(inputFile: str, outputFile: str, missingMatchesFilename: str):
    greeting_phrases = getPhrases()

    with open(inputFile, 'r', newline='', encoding='utf-8') as f_in, open(outputFile, 'w', newline='', encoding='utf-8') as f_out:
        total_lines = sum(1 for _ in f_in)  # count total lines
        print('total_lines: ' + str(total_lines))
        f_in.seek(0)  # reset the file pointer to the beginning
        tsv_reader = csv.DictReader(f_in, delimiter='\t')
        f_out.write("conv_id\tgreeting_text\n")  # write the header

        missing_matches = []
        for line_num, row in enumerate(tsv_reader, 1):
            greeting_text, missing_match = find_greeting(row['plain_whisper'], row['conv_id'], greeting_phrases, 0, 6)
            if greeting_text:  # only write to file if greeting_text is not empty
                f_out.write(f"{row['conv_id']}\t{greeting_text}\n")  # write the row

            if missing_match is not None:
                missing_matches.append(missing_match)

            print(f'Processed {line_num} / {total_lines} lines.')

    # Write all missing matches to the file at once
    with open(missingMatchesFilename, 'w', encoding='utf-8') as file:
        file.writelines(missing_matches)

#%%
dir = '/chunk-complaint/category/'
inputFilename = dir + 'train_data_v3_metadata.tsv'
outputFilename = dir + 'conv_greetings.txt'
missingMatchesFilename = dir + 'missing_greetings.txt'
save_greetings(inputFilename, outputFilename, missingMatchesFilename)